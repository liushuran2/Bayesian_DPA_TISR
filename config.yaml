#model settings
mid_channels: 64               #number of channels in residual blocks
extraction_nblocks: 3          #number of residual blocks in the extraction module
propagation_nblocks: 3         #number of residual blocks in the propagation module
reconstruction_nblocks: 5      #number of residual blocks in the reconstruction module
factor: 3                      #scale factor
bayesian: True                 #use bayesian DPA-TISR or non-bayesian

#dataset settings
train_dataset_path:        #dataset path
valid_dataset_path:        #dataset path
test_dataset_path: dataset/F-actin.h5         #dataset path
num_workers: 0              #num_workers

#training settings
batchsize: 3                              #batchsize
patch_size: 128                           #patch_size
checkpoint_folder: checkpt/F-actin      #the folder to save checkpoint
checkpoint_name: checkptx2.pt             #filename of checkpoint
hot_start: 0                              #0 for training from scratcsh, 1 for resume from a checkpoint
hot_start_checkpt: checkpt/F-actin/checkptx2.pt     #checkpoint used to resume training, if hot_start=0, this is ignored
epoch: 36000                               #number of training epochs, set to a large number and manually stop training if needed
N_save_checkpt: 200                       #save checkpoint every N_save_checkpt iterations
tensorboard_folder: tensorboard/F-actin

#inference settings
save_path: result
inference_checkpt: checkpt/F-actin_checkpt.pt     #checkpoint of testing
epsilon: 0.04                                       #hyperparameter of loss function
finetune_epoch: 30                                  #number of finetuning epochs

